{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb7c487",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this notebook, we'll preprocess the individual `.ndjson` source files before loading them into the graph database. Our eventual goal is to have a dataset that we can run inference and queries on to identify hotspots and gaps in local markets.\n",
    "\n",
    "Defining some paths first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feedec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROC_DIR = \"local_data/preproc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad9440",
   "metadata": {},
   "source": [
    "\n",
    "## Businesses\n",
    "\n",
    "Counting the total number of businesses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f77793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150346\n"
     ]
    }
   ],
   "source": [
    "BUSINESS_FILE = \"local_data/raw/business.ndjson\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(BUSINESS_FILE) as f:\n",
    "\tfor line in f: count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e14011e",
   "metadata": {},
   "source": [
    "\n",
    "### Sanitization\n",
    "\n",
    "We'll sanitize by fixing `repr`'d attributes and converting category strings to proper JSON arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd8f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, ast\n",
    "\n",
    "with open(BUSINESS_FILE) as fin, open(f\"{PREPROC_DIR}/business.ndjson\",\"w\") as fout:\n",
    "\tfor line in fin:\n",
    "\t\tb = json.loads(line)\n",
    "\n",
    "\t\t# parse full attributes object\n",
    "\t\tattrs = b.get(\"attributes\")\n",
    "\n",
    "\t\tif isinstance(attrs, dict):\n",
    "\t\t\tfor k, v in attrs.items():\n",
    "\t\t\t\tif isinstance(v, str):\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# fix python-repr'd attributes\n",
    "\t\t\t\t\ttry: b[\"attributes\"][k] = ast.literal_eval(v)\n",
    "\t\t\t\t\texcept Exception: pass\n",
    "\n",
    "\t\t# convert categories string to list\n",
    "\t\tcats = b.get(\"categories\")\n",
    "\t\tif isinstance(cats, str): b[\"categories\"] = [c.strip() for c in cats.split(',')]\n",
    "\n",
    "\t\tfout.write(json.dumps(b) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d66b1a",
   "metadata": {},
   "source": [
    "## Users\n",
    "\n",
    "Counting the total number of users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89796d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987897\n"
     ]
    }
   ],
   "source": [
    "USER_FILE = \"local_data/raw/user.ndjson\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open(USER_FILE) as f:\n",
    "\tfor line in f: count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1729a94",
   "metadata": {},
   "source": [
    "### Downsizing\n",
    "\n",
    "We've got far too many users to process in the short time span we have, so we'll need to figure out how to sample from the users in a way that satisfies our insight criteria. The idea here is this - we keep all the businesses in the dataset, and we select the top $n$% most relevant users for the richest possible dataset; finally, we'll filter reviews to only include those written by our selected users. This way, we preserve our primary vector - businesses - and downsize the overall database while preserving the links and relationships we need.\n",
    "\n",
    "We first create a users $\\to$ fans mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb7b222d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987897"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fans_map = {}\n",
    "\n",
    "with open(USER_FILE) as f:\n",
    "\tfor line in f:\n",
    "\t\tu = json.loads(line)\n",
    "\t\tfans_map[u[\"user_id\"]] = u.get(\"fans\", 0)\n",
    "\n",
    "# stability check - no. of fans = no. of users\n",
    "len(fans_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b7507",
   "metadata": {},
   "source": [
    "And next a business $\\leftarrow$ (reviewing) users mapping - also, we'll:\n",
    "\n",
    "- Check for dangling reviews from deleted users\n",
    "- Filter for data post 2015, just as an arbitrary \"makes sense\" cutoff\n",
    "\n",
    "We'll first define the cutoff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f01227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "cutoff = datetime(2017, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf19be6",
   "metadata": {},
   "source": [
    "And then create the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "821aa53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135542"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "REVIEW_FILE = \"local_data/raw/review.ndjson\"\n",
    "\n",
    "reviewers_map = defaultdict(set)\n",
    "\n",
    "with open(REVIEW_FILE) as f:\n",
    "\tfor line in f:\n",
    "\t\tr = json.loads(line)\n",
    "\n",
    "\t\t# parse datetime\n",
    "\t\tdt = datetime.strptime(r[\"date\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\t\t# add user if exists in users.ndjson (proxied by fans_map)\n",
    "\t\tif (r[\"user_id\"] in fans_map) and (dt > cutoff): reviewers_map[r[\"business_id\"]].add(r[\"user_id\"])\n",
    "\n",
    "# stability check - no. of entries <= no. of businesses\n",
    "len(reviewers_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319e612",
   "metadata": {},
   "source": [
    "Finally, get top $n$% of users for all businesses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aacb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357246"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "final_users = set()\n",
    "\n",
    "for b, users in reviewers_map.items():\n",
    "\tsorted_users = list(users)\n",
    "\n",
    "\t# sort users based on popularity\n",
    "\tsorted_users.sort(key=lambda uid: fans_map.get(uid, 0), reverse=True)\n",
    "\n",
    "\t# get top 100% and add to set\n",
    "\tfinal_users.update(sorted_users[:max(math.ceil(len(users) * 1.0), 0)])\n",
    "\n",
    "\tfinal_users.update(sorted_users)\n",
    "\n",
    "# count no. of chosen users\n",
    "len(final_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e25081",
   "metadata": {},
   "source": [
    "And now to create the preprocessed `.ndjson` file itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0061b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(USER_FILE) as fin, open(f\"{PREPROC_DIR}/user.ndjson\",\"w\") as fout:\n",
    "\tfor line in fin:\n",
    "\t\tu = json.loads(line)\n",
    "\n",
    "\t\t# select user if in final selection\n",
    "\t\tif u[\"user_id\"] in final_users:\t\n",
    "\n",
    "\t\t\t# make dates ISO compliant\n",
    "\t\t\tdt = datetime.strptime(u[\"yelping_since\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "\t\t\tu[\"yelping_since\"] = dt.isoformat() + \"Z\"\n",
    "\n",
    "\t\t\t# convert elite years string to list and fix 2020 error\n",
    "\t\t\telite = u.get(\"elite\")\n",
    "\t\t\tu[\"elite\"] = list(set(2020 if int(y) == 20 else int(y) for y in elite.split(\",\"))) if len(elite) else []\n",
    "\n",
    "\t\t\t# convert friends string to list, filter on final users\n",
    "\t\t\tfriends = u.get(\"friends\")\n",
    "\t\t\tu[\"friends\"] = [f.strip() for f in friends.split(\",\") if f.strip() in final_users]\n",
    "\t\t\t\n",
    "\t\t\tfout.write(json.dumps(u) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6e75f",
   "metadata": {},
   "source": [
    "## Reviews\n",
    "\n",
    "Counting the total number of reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1d70e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6990280\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "with open(REVIEW_FILE) as f:\n",
    "\tfor line in f: count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48dfd3",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "We'll go ahead and filter reviews by those written by our selected users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f87c4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of reviewers: 1357246\n",
      "No. of reviews: 3838072\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "unique_reviewers = set()\n",
    "\n",
    "with open(REVIEW_FILE) as fin, open(f\"{PREPROC_DIR}/review.ndjson\",\"w\") as fout:\n",
    "\tfor line in fin:\n",
    "\t\tr = json.loads(line)\n",
    "\n",
    "\t\t# parse datetime\n",
    "\t\tdt = datetime.strptime(r[\"date\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\t\t# get reviewer user id\n",
    "\t\treviewer_id = r[\"user_id\"]\n",
    "\n",
    "\t\t# select review if author in final selection\n",
    "\t\tif reviewer_id in final_users and dt > cutoff: \n",
    "\t\t\tcount += 1\n",
    "\t\t\tunique_reviewers.add(reviewer_id)\n",
    "\t\t\t\n",
    "\t\t\t# make dates ISO compliant\n",
    "\t\t\tr[\"date\"] = dt.isoformat() + \"Z\"\n",
    "\n",
    "\t\t\tfout.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "# stability check - no. of reviewers = no. of selected users\n",
    "print(f\"No. of reviewers: {len(unique_reviewers)}\")\n",
    "\n",
    "print(f\"No. of reviews: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e070291",
   "metadata": {},
   "source": [
    "## Final Checks\n",
    "\n",
    "We'll now run some final checks to factualize any remaining assumptions about the data.\n",
    "\n",
    "### Bidirectional Friendship\n",
    "\n",
    "We'll check if it's implied that given $A$ is a friend of $B$, then $B$ is a friend of $A$. We'll create a user $\\to$ friends map first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22749631",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_map = {}\n",
    "\n",
    "with open(f\"{PREPROC_DIR}/user.ndjson\") as f:\n",
    "\tfor line in f:\n",
    "\t\tu = json.loads(line)\n",
    "\t\t\n",
    "\t\tfriend_map[u[\"user_id\"]] = u[\"friends\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667b559",
   "metadata": {},
   "source": [
    "And then run the verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87daa89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, friends in friend_map.items():\n",
    "\tfor friend in friends:\n",
    "\t\tif user not in friend_map[friend]: print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290c3ca",
   "metadata": {},
   "source": [
    "No output, so looks solid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d39fc",
   "metadata": {},
   "source": [
    "### User Relevancy\n",
    "\n",
    "How important is a user to our inference task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c55d051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357246"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_map = {}\n",
    "\n",
    "with open(f\"{PREPROC_DIR}/user.ndjson\") as f:\n",
    "\tfor line in f:\n",
    "\t\tu = json.loads(line)\n",
    "\t\treviews_map[u[\"user_id\"]] = u.get(\"review_count\", 0)\n",
    "\n",
    "# stability check - no. of review counts = no. of users\n",
    "len(reviews_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a803e98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170917"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for user, friends in friend_map.items():\n",
    "\tif not len(friends) and reviews_map[user] < 2: count += 1\n",
    "\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
